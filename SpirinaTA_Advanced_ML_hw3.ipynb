{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled15.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Спирина Татьяна DS-22\n",
        "\n"
      ],
      "metadata": {
        "id": "zqWemY2_fM6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import random\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "AhGy6927fOlK"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tTfj19_mGZp",
        "outputId": "738a3b69-a1aa-4626-d927-548b0a9ac0a3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **1. Реализуйте базовый частотный метод по Шерлоку Холмсу:**\n",
        "\n",
        "**подсчитайте частоты букв по корпусам (пунктуацию и капитализацию можно просто опустить, а вот пробелы лучше оставить);**\n",
        "\n",
        "**возьмите какие-нибудь тестовые тексты (нужно взять по меньшей мере 2-3 предложения, иначе вряд ли сработает), зашифруйте их посредством случайной перестановки символов;**\n",
        "\n",
        "**расшифруйте их таким частотным методом.**"
      ],
      "metadata": {
        "id": "u9lDL0SAfNWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/gdrive/MyDrive/WarAndPeace.txt\", \"r\") as f:\n",
        "    war_and_peace = f.read()\n"
      ],
      "metadata": {
        "id": "Zmb4BROvll_F"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ahsAk7QEfGak"
      },
      "outputs": [],
      "source": [
        "TEST_TEXT = \"А человек такая скотина, он ко всему привыкает. Поставь на него ногу, он годик побрыкается, а на второй привыкнет. Надень на него сбрую – и через год он научится распознавать овес по урожайным годам и чавкать с видом знатока. Отними у него все – и очень скоро он объявит это свободой.\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_clean(text):\n",
        "  return re.sub(r\"\\W+\", \" \", text).lower() "
      ],
      "metadata": {
        "id": "B_povhElifyL"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_TEXT = text_clean(TEST_TEXT)\n",
        "TEST_TEXT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "BCrqpPkOikxR",
        "outputId": "f903d455-6a61-4ab3-d5fb-e40e41226f1d"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'а человек такая скотина он ко всему привыкает поставь на него ногу он годик побрыкается а на второй привыкнет надень на него сбрую и через год он научится распознавать овес по урожайным годам и чавкать с видом знатока отними у него все и очень скоро он объявит это свободой '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_frequencies(text):\n",
        "    freqs = {}\n",
        "    for letter in text:\n",
        "      if letter in freqs:\n",
        "        freqs[letter] += 1\n",
        "      else: \n",
        "        freqs[letter] = 1\n",
        "    return freqs"
      ],
      "metadata": {
        "id": "LCxVTAb9khFZ"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Зашифровываем текст"
      ],
      "metadata": {
        "id": "wIbsxPivs9uW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(text): \n",
        "  freq_counted = count_frequencies(text)\n",
        "  true_alphabet = sorted(freq_counted.keys())\n",
        "  shuffled_alphabet = true_alphabet.copy()\n",
        "  random.shuffle(shuffled_alphabet)\n",
        "  \n",
        "  encoded = \"\"\n",
        "  for letter in text:\n",
        "    encoded += shuffled_alphabet[true_alphabet.index(letter)]\n",
        "  return encoded"
      ],
      "metadata": {
        "id": "T1-GsyosqDHS"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_text = encode(TEST_TEXT)\n",
        "encoded_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "CmRVWV7Ltq-y",
        "outputId": "1377dee4-1f75-4d21-9299-25aa73b36a47"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'амсчрвжчнмпанаюмтнвпуыамвымнвмжтчэьмйоуж начпмйвтпажгмыамычевмывеьмвымевъунмйвяо начптюмамыамжпвовкмйоуж нычпмыаъчыгмыамычевмтяоьзмумсчочдмевъмвымыаьсуптюмоатйвдыажапгмвжчтмйвмьовбакы эмевъаэмумсажнапгмтмжуъвэмдыапвнамвпыуэумьмычевмжтчмумвсчыгмтнвовмвымвялюжупмипвмтжвявъвкм'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "На основе Войны и Мира сформируем частоты символов для русского алфавита"
      ],
      "metadata": {
        "id": "hP5kX5VPuKdK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reference_freq = count_frequencies(text_clean(war_and_peace))"
      ],
      "metadata": {
        "id": "8MKW7020uSFr"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reference_dict = {}\n",
        "sorted_keys = sorted(reference_freq, key=reference_freq.get, reverse=True) \n",
        "\n",
        "ru_alph = [i for i in range(ord('а'), ord('я')+1)]\n",
        "ru_alph.append(ord(\" \"))\n",
        "\n",
        "for l in sorted_keys:\n",
        "  if ord(l) in ru_alph:\n",
        "    reference_dict[l] = reference_freq[l]\n",
        "\n",
        "print(reference_dict) \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IitE3iZ1u2Oz",
        "outputId": "f6f9ee5f-b913-4ca9-b43c-6107fb279b19"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{' ': 111185, 'о': 61282, 'а': 45209, 'е': 42519, 'и': 35838, 'н': 35119, 'т': 30619, 'с': 28128, 'л': 27277, 'в': 24824, 'р': 24570, 'к': 19328, 'д': 16387, 'м': 15940, 'у': 15454, 'п': 13847, 'я': 12477, 'г': 11177, 'ь': 10498, 'ы': 10233, 'з': 9602, 'б': 9310, 'ч': 7349, 'й': 6210, 'ж': 5460, 'ш': 5090, 'х': 4600, 'ю': 3495, 'ц': 2179, 'э': 1629, 'щ': 1514, 'ф': 1209, 'ъ': 283}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Частотность на основе Войны и Мира близка, но не на 100% совпадает с данными \"частотность букв русского языка\" из википедии. "
      ],
      "metadata": {
        "id": "IturQUbQvlj2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Определяем частоту символов в закодированном предложении"
      ],
      "metadata": {
        "id": "ctx8If4s6rhF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "enc_freq_counted = count_frequencies(encoded_text)\n",
        "encoded_dict = {}\n",
        "sorted_keys = sorted(enc_freq_counted, key=enc_freq_counted.get, reverse=True) \n",
        "    \n",
        "for l in sorted_keys:\n",
        "    encoded_dict[l] = enc_freq_counted[l]\n",
        "\n",
        "print(encoded_dict) \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjoF1iorwjAB",
        "outputId": "1774c3ab-07d7-4987-d1f0-14f0a1e419d7"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'м': 49, 'в': 33, 'а': 22, 'ы': 21, 'ч': 15, 'п': 14, 'ж': 13, 'т': 12, 'у': 12, 'н': 11, 'о': 9, 'е': 7, 'ь': 6, 'й': 6, 'ъ': 6, 'с': 5, 'э': 5, 'г': 5, 'ю': 4, ' ': 4, 'я': 4, 'к': 3, 'д': 3, 'р': 1, 'з': 1, 'б': 1, 'л': 1, 'и': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сопоставляем символы по частоте из закодированного текста и шаблона частот Войны и Мира"
      ],
      "metadata": {
        "id": "ATQ5qVTz6zWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reference_letters = list(reference_dict.keys())\n",
        "encoded_letters = list(encoded_dict.keys())\n",
        "decode_dict = dict(zip(encoded_letters, reference_letters))"
      ],
      "metadata": {
        "id": "tPE3QFTn7BIZ"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decode_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IoPPwo5MSSd",
        "outputId": "9559e447-1e1b-4629-f7ca-df2cfda8665a"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ': 'ы',\n",
              " 'а': 'а',\n",
              " 'б': 'ш',\n",
              " 'в': 'о',\n",
              " 'г': 'г',\n",
              " 'д': 'ч',\n",
              " 'е': 'к',\n",
              " 'ж': 'т',\n",
              " 'з': 'ж',\n",
              " 'и': 'ю',\n",
              " 'й': 'м',\n",
              " 'к': 'б',\n",
              " 'л': 'х',\n",
              " 'м': ' ',\n",
              " 'н': 'в',\n",
              " 'о': 'р',\n",
              " 'п': 'н',\n",
              " 'р': 'й',\n",
              " 'с': 'п',\n",
              " 'т': 'с',\n",
              " 'у': 'л',\n",
              " 'ч': 'и',\n",
              " 'ъ': 'у',\n",
              " 'ы': 'е',\n",
              " 'ь': 'д',\n",
              " 'э': 'я',\n",
              " 'ю': 'ь',\n",
              " 'я': 'з'}"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_text(text, decode_dict):\n",
        "  decoded = \"\"\n",
        "  for letter in text:\n",
        "     decoded += decode_dict[letter]\n",
        "  return decoded"
      ],
      "metadata": {
        "id": "7A_Sojw-xWID"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_sherlock = decode_text(encoded_text, decode_dict)\n",
        "decoded_sherlock"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "bqLr3x1h7qCf",
        "outputId": "02dbf434-a845-4f33-9221-f62e52e8efbd"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'а пийотив наваь свонлеа ое во тсияд мрлтываин моснатг еа еико еокд ое коулв мозрываинсь а еа тнороб мрлтывеин еауиег еа еико сзрдж л пирич коу ое еадплнсь расмочеатанг отис мо дрошабеыя коуая л патванг с тлуоя чеанова онелял д еико тси л опиег своро ое озхьтлн юно стозоуоб '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "На глаз не читабельно, хотя видно, что буква \"а\", например, подобралась. Посмотрю какие буквы встали на свое место, а так же условную accuracy относительно всего текста."
      ],
      "metadata": {
        "id": "VR2ewH4ky3yA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def correct_symbols(true_text, decoded_text):\n",
        "  correct = set()\n",
        "  for i in range(len(true_text)):\n",
        "    if true_text[i] == decoded_text[i]:\n",
        "      correct.add(true_text[i])\n",
        "     \n",
        "  return correct"
      ],
      "metadata": {
        "id": "Kks-dHTvzIww"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(true_text, decoded_text):\n",
        "    correct = 0\n",
        "    for l1, l2 in zip(true_text, decoded_text):\n",
        "        if l1 == l2:\n",
        "            correct += 1\n",
        "    return correct / len(true_text)"
      ],
      "metadata": {
        "id": "N-VtX_KtA66H"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(correct_symbols(TEST_TEXT, decoded_sherlock))\n",
        "print(accuracy(TEST_TEXT, decoded_sherlock))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOx5fjG5A90m",
        "outputId": "3f7563da-e035-4041-8a8c-5fce3799a474"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'а', 'с', 'о', 'р', ' ', 'ы'}\n",
            "0.4708029197080292\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Совпали 6 символом и показатель accuracy, казалось бы, не плох. Но, наверно, дело в том, что угадались частые буквы типа а и пробела. В принципе, для последующего подбора текста методом Шерклока Холмса, это должо быть хорошим стартом. Но на глаз не читабельно."
      ],
      "metadata": {
        "id": "FPEQcKvu70Bb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Попробую захардкоженный словарь частотности, на основе данных википедии"
      ],
      "metadata": {
        "id": "iS_SU6Y28dWb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reference_letters_nkrya = [\" \", \"о\", \"е\", \"а\", \"и\", \"н\", \"т\", \"с\", \"р\", \"в\", \"л\", \"к\", \"м\", \"д\", \"п\", \"у\", \"я\", \"ы\", \"ь\", \"г\", \"з\", \"б\", \"ч\", \"й\", \"х\", \"ж\", \"ш\", \"ю\", \"ц\", \"щ\", \"э\", \"ф\", \"ъ\", \"ё\"]\n",
        "decode_dict_nkrya = dict(zip(encoded_letters, reference_letters_nkrya))\n",
        "decoded_nkrya = decode_text(encoded_text, decode_dict_nkrya )\n",
        "print(correct_symbols(TEST_TEXT, decoded_nkrya))\n",
        "print(accuracy(TEST_TEXT, decoded_nkrya))"
      ],
      "metadata": {
        "id": "0oxFIa9h8nLw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a4e6662-4228-4156-9773-3496fa5de6a9"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'с', 'о', ' ', 'ж'}\n",
            "0.3467153284671533\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Любопытно, что результат вышел даже хуже. Вероятно, зависит от изначального текста. Цитата Достоевского больше подошла к частоте на основе Войны и Мира. Частота той же буквы \"а\" одинакова для Достоевского и Толстого, но не Достоевского и национального корпуса русского языка. Забавно."
      ],
      "metadata": {
        "id": "2FxsWbs89nxV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.Вряд ли в результате получилась такая уж хорошая расшифровка, разве что если вы брали в качестве тестовых данных целые рассказы. Но и Шерлок Холмс был не так уж прост: после буквы E, которая действительно выделяется частотой, дальше он анализировал уже конкретные слова и пытался угадать, какими они могли бы быть. Я не знаю, как запрограммировать такой интуитивный анализ, так что давайте просто сделаем следующий логический шаг:**\n",
        "\n",
        "**подсчитайте частоты биграмм (т.е. пар последовательных букв) по корпусам;\n",
        "проведите тестирование аналогично п.1, но при помощи биграмм.**\n"
      ],
      "metadata": {
        "id": "Sr6Iok8499As"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_bigram_frequencies(text):\n",
        "    freqs = {}\n",
        "    exists_symbols = set([l for l in text])\n",
        "\n",
        "    for s1 in exists_symbols:\n",
        "        for s2 in exists_symbols:\n",
        "            freqs[s1 + s2] = 0\n",
        "\n",
        "    for i in range(len(text) - 1):\n",
        "      if text[i] in exists_symbols and text[i+1] in exists_symbols:\n",
        "        freqs[text[i] + text[i+1]] += 1\n",
        "    return freqs\n"
      ],
      "metadata": {
        "id": "wnWG5zUnBADG"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reference_bigram_freqs = count_bigram_frequencies(text_clean(war_and_peace))\n",
        "encoded_bigram_freqs = count_bigram_frequencies(encoded_text)"
      ],
      "metadata": {
        "id": "beE1maoZBVJN"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_reference_bigrams_alphabet= {}\n",
        "sorted_keys = sorted(reference_bigram_freqs, key=reference_bigram_freqs.get, reverse=True) \n",
        "for l in sorted_keys:\n",
        "    sorted_reference_bigrams_alphabet[l] = reference_bigram_freqs[l]\n",
        "\n",
        "\n",
        "sorted_encoded_bigrams_alphabet= {}\n",
        "sorted_keys = sorted(encoded_bigram_freqs, key=encoded_bigram_freqs.get, reverse=True) \n",
        "for l in sorted_keys:\n",
        "    sorted_encoded_bigrams_alphabet[l] = encoded_bigram_freqs[l]"
      ],
      "metadata": {
        "id": "EWvBnV75B93w"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Честно говоря, вообще не понятно как это должно дальше работать. Логично, что на большом корпусе биграмм с пробелами будет ощутимое количество, тогда как на тестовом это не так. Надолго зависла на этом шаге. Не понимаю как правильно реализовать дешифровку. \n",
        "Сначала сформируем словарь соответсвия частоты биграмм из нашего закодированного текста и Войны и мира. Разные мысли не приводили ни к чему, оставила самую простую версию и перехожу к мсмс."
      ],
      "metadata": {
        "id": "DhLLJnr33det"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bigramm_accordance = dict(zip(list(sorted_encoded_bigrams_alphabet.keys()), list(sorted_reference_bigrams_alphabet.keys())))"
      ],
      "metadata": {
        "id": "-liWukK547W0"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "decoded_text = \"\"\n",
        "decoded_text += bigramm_accordance[encoded_text[:2]]\n",
        "for i in range(1, len(TEST_TEXT)-1):\n",
        "  decoded_text += bigramm_accordance[encoded_text[i:i+2]][1]\n",
        "\n"
      ],
      "metadata": {
        "id": "P4jOm89-XHgd"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "F6bI25lb4jp7",
        "outputId": "99b27d84-ce9b-43ee-9dac-31f3794514ad"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'е алмзсмяоба н оо   еэ    т  саьерироти л нлоооиетаойв     тпс тмар  тбпкееооиачв нлогро     аодивнноти л я оо  есмав     тпсоич в  оалстербпка  т  еугнгроускьиыа оееив смалоисривйндеоиобпкяро оатоннеиволакдасоыа еден   мооьорр  тпсаьеи о улмаво  ивс  т алгзкнонедсо лаыканн'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(correct_symbols(TEST_TEXT, decoded_text))\n",
        "print(accuracy(TEST_TEXT, decoded_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QTk-3Eb4hHE",
        "outputId": "75a65f61-5d1a-4865-a7cc-331205defb06"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'е', 'а', 'д', ' ', 'т', 'и'}\n",
            "0.058394160583941604\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Какие-то буквы где-то в тексте угадались (вообще для биграмм этот метод оценки не применим, было интересно какие хоть где-то буквы совпали), но результат по accuracy ужасен. Читабельность \"на глаз\" что там, что тут отсутствует."
      ],
      "metadata": {
        "id": "TwXW7Fcq7lbg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **3.Но и это ещё не всё: биграммы скорее всего тоже далеко не всегда работают. Основная часть задания — в том, как можно их улучшить:\n",
        "предложите метод обучения перестановки символов в этом задании, основанный на MCMC-сэмплировании, но по-прежнему работающий на основе статистики биграмм;\n",
        "реализуйте и протестируйте его, убедитесь, что результаты улучшились**\n"
      ],
      "metadata": {
        "id": "_Tb90d3CDeJA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Отталкиваясь от начального положения рандомно переставляем значение символов в словаре декодирования. Считаем логарифм правдоподобия расшифрованного сообщения на основе его биграмм и их частот в Войне и Мире. Если он стал больше предыдущего, то фиксируем перестановку символов и новый словарь декодирования, который будет использоваться не следующей итерации. Если нет, то для принятия решения фиксировать или нет \"бросаем монетку\". В качестве начального положения беру словарь соответствия символов аналогично 1му пункту, вероятно надо было брать какой-то результат по 2му пункту, но моя реализация 2го пункта, мягко говоря, не внушает доверия"
      ],
      "metadata": {
        "id": "vWaD4QTa1Tio"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dict_sample(cur_dict):\n",
        "    new_dict = cur_dict.copy()\n",
        "    i,j = (random.choices(list(cur_dict.keys()), k=2))\n",
        "    new_dict[i], new_dict[j] = cur_dict[j], cur_dict[i]\n",
        "    return new_dict\n",
        "\n",
        "def likelihood(cur_dict, encoded_text, bigrams_alphabet=sorted_reference_bigrams_alphabet):\n",
        "  decoded_text = decode_text(encoded_text, cur_dict)\n",
        "  bigramm_text = count_bigram_frequencies(decoded_text)\n",
        "  \n",
        "  count_l = 0\n",
        "  for bigram, v in bigramm_text.items():\n",
        "    count_l += v * np.log(max(bigrams_alphabet[bigram], 0.0001))\n",
        "\n",
        "  return count_l\n",
        "\n",
        "# Функции из ноутбука с 10й лекции:\n",
        "def metropolis_hastings_log_accept(l, l_new):\n",
        "    if l_new>l:\n",
        "        return True\n",
        "    else:\n",
        "        return (np.random.rand() < (np.exp(l_new-l)))\n",
        "\n",
        "def metropolis_hastings(encoded_text, iterations, init_x, print_acc = True):\n",
        "    iter = 0\n",
        "    print(decode_text(encoded_text, init_x))\n",
        "\n",
        "    cur_x = init_x\n",
        "    cur_l = likelihood(cur_x, encoded_text,)\n",
        "    samples, accept_bit = [cur_x], [1]\n",
        "    for i in range(iterations):\n",
        "        iter += 1\n",
        "        new_x = dict_sample(cur_x)\n",
        "        new_l = likelihood(new_x, encoded_text,)\n",
        "        samples.append(new_x)\n",
        "        if (metropolis_hastings_log_accept(cur_l, new_l)):\n",
        "            cur_x, cur_l = new_x, new_l\n",
        "            accept_bit.append(1)\n",
        "        else:\n",
        "            accept_bit.append(0)\n",
        "        if iter %10000 == 0:\n",
        "          decoded = decode_text(encoded_text, cur_x)\n",
        "          if print_acc:\n",
        "            print(\"accuracy\", accuracy(TEST_TEXT, decoded))\n",
        "          print(\"iter\", iter, decoded)\n",
        "          \n",
        "    return cur_x\n",
        "\n"
      ],
      "metadata": {
        "id": "WEkqtaTXqSFK"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_decrypt_dict = metropolis_hastings(encoded_text, iterations=200000, init_x=decode_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90QVQpKQud96",
        "outputId": "ee2199ad-c269-4795-ec4d-2bb62c673118"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "а пийотив наваь свонлеа ое во тсияд мрлтываин моснатг еа еико еокд ое коулв мозрываинсь а еа тнороб мрлтывеин еауиег еа еико сзрдж л пирич коу ое еадплнсь расмочеатанг отис мо дрошабеыя коуая л патванг с тлуоя чеанова онелял д еико тси л опиег своро ое озхьтлн юно стозоуоб \n",
            "accuracy 0.7773722627737226\n",
            "iter 10000 а чешотев лаваю сволина он во тсему критываел кослатя на него ногу он годив копрываелсю а на тлорой критывнел наденя на него спрух и через год он научилсю раскознаталя отес ко урожайным годам и чатваля с тидом зналова олними у него тсе и оченя своро он опьютил бло стоподой \n",
            "accuracy 0.7627737226277372\n",
            "iter 20000 а чезотев лаваю сволина он во тсему критываел кослатя на него ногу он годив копрываелсю а на тлорой критывнел наденя на него спрух и череж год он научилсю раскожнаталя отес ко уробайным годам и чатваля с тидом жналова олними у него тсе и оченя своро он опьютил шло стоподой \n",
            "accuracy 0.8321167883211679\n",
            "iter 30000 а жехотек лакая сколина он ко тсему притыкаел послать на него ногу он говик подрыкаелся а на тлорой притыкнел навень на него сдрую и жерез гов он наужился распознаталь отес по урочайным говам и жаткаль с тивом зналока олними у него тсе и ожень скоро он одбятил шло стодовой \n",
            "accuracy 0.8540145985401459\n",
            "iter 40000 а чехотек лакая сколина он ко тсему притыкаел послать на него ногу он говик подрыкаелся а на тлорой притыкнел навень на него сдрую и через гов он научился распознаталь отес по урожайным говам и чаткаль с тивом зналока олними у него тсе и очень скоро он одбятил шло стодовой \n",
            "accuracy 0.8540145985401459\n",
            "iter 50000 а чехотек лакая сколина он ко тсему притыкаел послать на него ногу он говик подрыкаелся а на тлорой притыкнел навень на него сдрую и через гов он научился распознаталь отес по урожайным говам и чаткаль с тивом зналока олними у него тсе и очень скоро он одбятил шло стодовой \n",
            "accuracy 0.8540145985401459\n",
            "iter 60000 а чехотек лакая сколина он ко тсему притыкаел послать на него ногу он говик подрыкаелся а на тлорой притыкнел навень на него сдрую и через гов он научился распознаталь отес по урожайным говам и чаткаль с тивом зналока олними у него тсе и очень скоро он одбятил шло стодовой \n",
            "accuracy 0.8540145985401459\n",
            "iter 70000 а чехотек лакая сколина он ко тсему притыкаел послать на него ногу он говик подрыкаелся а на тлорой притыкнел навень на него сдрую и через гов он научился распознаталь отес по урожайным говам и чаткаль с тивом зналока олними у него тсе и очень скоро он одбятил шло стодовой \n",
            "accuracy 0.8613138686131386\n",
            "iter 80000 а чехотек лакая сколина он ко тсему притыкаел послать на него ногу он годик поврыкаелся а на тлорой притыкнел надень на него сврую и череж год он научился распожнаталь отес по урошайным годам и чаткаль с тидом жналока олними у него тсе и очень скоро он овзятил бло стоводой \n",
            "accuracy 0.9306569343065694\n",
            "iter 90000 а жеховек такая скотина он ко всему привыкает поставь на него ногу он голик подрыкается а на второй привыкнет налень на него сдрую и жерез гол он наужится распознавать овес по урошайным голам и жавкать с вилом знатока отними у него все и ожень скоро он одбявит что сводолой \n",
            "accuracy 0.8211678832116789\n",
            "iter 100000 а чехотек лакая сколина он ко тсему притькаел послаты на него ногу он говик подрькаелся а на тлорой притькнел навены на него сдрую и через гов он научился распознаталы отес по урожайньм говам и чаткалы с тивом зналока олними у него тсе и очены скоро он одбятил шло стодовой \n",
            "accuracy 0.8868613138686131\n",
            "iter 110000 а чеховет латая столина он то всему привытаел пославь на него ногу он годит побрытаелся а на влорой привытнел надень на него сбрую и черек год он научился распокнаваль овес по урожайным годам и чавталь с видом кналота олними у него все и очень сторо он обзявил шло свободой \n",
            "accuracy 0.8540145985401459\n",
            "iter 120000 а чехотек лакая сколина он ко тсему притыкаел послать на него ногу он говик подрыкаелся а на тлорой притыкнел навень на него сдрую и через гов он научился распознаталь отес по урожайным говам и чаткаль с тивом зналока олними у него тсе и очень скоро он одбятил шло стодовой \n",
            "accuracy 0.8540145985401459\n",
            "iter 130000 а чехотек лакая сколина он ко тсему притыкаел послать на него ногу он говик подрыкаелся а на тлорой притыкнел навень на него сдрую и через гов он научился распознаталь отес по урожайным говам и чаткаль с тивом зналока олними у него тсе и очень скоро он одбятил шло стодовой \n",
            "accuracy 0.9014598540145985\n",
            "iter 140000 а чеховек лакая сколина он ко всему привыкаел пославь на него ногу он готик подрыкаелся а на влорой привыкнел натень на него сдрую и через гот он научился распознаваль овес по урожайным готам и чавкаль с витом зналока олними у него все и очень скоро он одбявил шло сводотой \n",
            "accuracy 0.8613138686131386\n",
            "iter 150000 а чеховет латая столина он то всему привытаел пославь на него ногу он гокит подрытаелся а на влорой привытнел накень на него сдрую и через гок он научился распознаваль овес по урожайным гокам и чавталь с виком зналота олними у него все и очень сторо он одбявил шло сводокой \n",
            "accuracy 0.8540145985401459\n",
            "iter 160000 а чехотек лакая сколина он ко тсему притыкаел послать на него ногу он говик подрыкаелся а на тлорой притыкнел навень на него сдрую и через гов он научился распознаталь отес по урожайным говам и чаткаль с тивом зналока олними у него тсе и очень скоро он одбятил шло стодовой \n",
            "accuracy 0.8065693430656934\n",
            "iter 170000 а чехотек лакая сколина он ко тсему притькаел послаты на него ногу он говик подрькаелся а на тлорой притькнел навены на него сдрую и череж гов он научился распожнаталы отес по урошайньм говам и чаткалы с тивом жналока олними у него тсе и очены скоро он одзятил бло стодовой \n",
            "accuracy 0.8211678832116789\n",
            "iter 180000 а чехотев лавая сволина он во тсему притываел послать на него ногу он годив покрываелся а на тлорой притывнел надень на него скрую и череж год он научился распожнаталь отес по урошайным годам и чатваль с тидом жналова олними у него тсе и очень своро он окзятил бло стокодой \n",
            "accuracy 0.8211678832116789\n",
            "iter 190000 а чехотек лакая сколина он ко тсему притькаел послаты на него ногу он говик подрькаелся а на тлорой притькнел навены на него сдрую и через гов он научился распознаталы отес по урожайньм говам и чаткалы с тивом зналока олними у него тсе и очены скоро он одбятил шло стодовой \n",
            "accuracy 0.8868613138686131\n",
            "iter 200000 а чебовек лакая сколина он ко всему привыкаел пославь на него ногу он готик подрыкаелся а на влорой привыкнел натень на него сдрую и череж гот он научился распожнаваль овес по урохайным готам и чавкаль с витом жналока олними у него все и очень скоро он одзявил шло сводотой \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Магия! Видно, что результат не очень стабилен. Полную картину легче получить почитав результаты нескольких итераций. Где-то одно слово лучше, где-то другое. Так же качество зависит от рандома. Но вообще - впечатляет."
      ],
      "metadata": {
        "id": "4oxf1AGGhBeZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_mcmc = decode_text(encoded_text, result_decrypt_dict)\n",
        "print(decoded_mcmc)\n",
        "print(correct_symbols(TEST_TEXT, decoded_mcmc ))\n",
        "print(accuracy(TEST_TEXT, decoded_mcmc ))\n",
        "print(\"Не распознано символов:\", 33 - len(correct_symbols(TEST_TEXT, decoded_mcmc )))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNrsPCMujM03",
        "outputId": "aa70255f-40a3-4798-a0b5-a76ec380151c"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "а чебовек лакая сколина он ко всему привыкаел пославь на него ногу он готик подрыкаелся а на влорой привыкнел натень на него сдрую и череж гот он научился распожнаваль овес по урохайным готам и чавкаль с витом жналока олними у него все и очень скоро он одзявил шло сводотой \n",
            "{'с', 'и', 'е', 'а', 'ю', 'р', 'к', 'в', 'й', 'г', 'ы', 'о', ' ', 'н', 'м', 'ч', 'п', 'я', 'ь', 'у'}\n",
            "0.8868613138686131\n",
            "Не распознано символов: 13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.Расшифруйте сообщение"
      ],
      "metadata": {
        "id": "cQkUL5T59lyb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TASK = \"დჳჵჂႨშႼႨშჂხჂჲდႨსႹႭჾႣჵისႼჰႨჂჵჂႨႲႹႧჲჂႨსႹႭჾႣჵისႼჰႨჲდႩჳჲႨჇႨႠჲႹქႹႨჳႹႹჱჶდსჂႽႨႩႹჲႹႭႼჰႨჵდქႩႹႨႲႭႹႧჂჲႣჲიႨჳႩႹႭდდႨშჳდქႹႨშႼႨშჳდႨჳხდჵႣჵჂႨႲႭႣშჂჵისႹႨჂႨႲႹჵჇႧჂჲდႨჾႣႩჳჂჾႣჵისႼჰႨჱႣჵჵႨეႣႨႲႹჳჵდხსდდႨႧდჲშდႭჲႹდႨეႣხႣსჂდႨႩჇႭჳႣႨႾႹჲႽႨႩႹსდႧსႹႨႽႨსჂႧდქႹႨსდႨႹჱდჶႣნ\""
      ],
      "metadata": {
        "id": "d1FpasjW9xQA"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task_freq = count_frequencies(TASK)\n",
        "\n",
        "task_dict = {}\n",
        "sorted_keys = sorted(task_freq, key=task_freq.get, reverse=True) \n",
        "print(len(sorted_keys), sorted_keys)\n",
        "print(len(reference_letters), reference_letters)\n",
        "for l in sorted_keys:\n",
        "    task_dict[l] = task_freq[l]\n",
        "\n",
        "encoded_letters = list(task_dict.keys())\n",
        "decode_task_dict = dict(zip(encoded_letters, reference_letters))\n",
        "print(len(decode_task_dict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGIsF4_i-RmI",
        "outputId": "66adec5e-f3c8-4d22-9c80-4299dccb0078"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28 ['Ⴈ', 'დ', 'Ⴙ', 'Ⴢ', 'ჵ', 'ს', 'Ⴃ', 'ჲ', 'ჳ', 'Ⴍ', 'შ', 'Ⴉ', 'Ⴜ', 'Ⴇ', 'ი', 'Ⴒ', 'ხ', 'ჾ', 'ჰ', 'ქ', 'Ⴧ', 'ჱ', 'Ⴝ', 'ჶ', 'ე', 'Ⴀ', 'Ⴞ', 'ნ']\n",
            "33 [' ', 'о', 'а', 'е', 'и', 'н', 'т', 'с', 'л', 'в', 'р', 'к', 'д', 'м', 'у', 'п', 'я', 'г', 'ь', 'ы', 'з', 'б', 'ч', 'й', 'ж', 'ш', 'х', 'ю', 'ц', 'э', 'щ', 'ф', 'ъ']\n",
            "28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для меня еще был вопрос на тему разницы количества символов в словаре закодированной фразы и войны и мира. В изначальной версии получились выкинуты буквы ц, э, ф, щ, ъ, что вообще-то не правда. Дополняла \"силой\" словарь. Но, честно говоря, не поняла дает это что-то или нет. В моем случае, кажется, сила рандома в итоге влияет больше."
      ],
      "metadata": {
        "id": "XiXBVqFBajoB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_decrypt_dict_task = metropolis_hastings(TASK, iterations=200000, init_x=decode_task_dict, print_acc = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baTvS5ug93m4",
        "outputId": "e1f4a1a8-0db1-4782-bcb8-078ca5cb5b98"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "олие рд реяесо навгтиундь еие памсе навгтиундь соклс з шсаыа лаабйонеч касавдь иоыка пваместсу лкавоо рлоыа рд рло ляоитие пвтреиуна е паизмесо гтклегтиундь бтии жт палиояноо мосровсао жтятнео кзвлт хасч каномна ч немоыа но абойтю\n",
            "iter 10000 ерио пт погосе навуликнть оио замсо навуликнть седрс я йсажа раачшеною дасавть иежда звамослск рдавее прежа пт пре ргеилио звлпоикна о заиямосе улдроуликнть члии бл зариегнее меспевсае блглное дяврл хасю данемна ю номежа не ачешлы\n",
            "iter 20000 ерио пт погосе навуликнть оио замсо навуликнть седрс я йсажа раачшеною дасавть иежда звамослск рдавее прежа пт пре ргеилио звлпоикна о заиямосе улдроуликнть члии бл зариегнее меспевсае блглное дяврл хасю данемна ю номежа не ачешлы\n",
            "iter 30000 ерио пт погосе навуликнть оио замсо навуликнть седрс я йсажа раачшеною дасавть иежда звамослск рдавее прежа пт пре ргеилио звлпоикна о заиямосе улдроуликнть члии бл зариегнее меспевсае блглное дяврл хасю данемна ю номежа не ачешлы\n",
            "iter 40000 ерти пы пишиле носчатьный ити вомли носчатьный лекрл у блого роождения колосый тегко всомилаль ркосее прего пы пре ршетати всапитьно и вотумиле чакричатьный жатт за вортешнее мелпеслое зашание кусра холя конемно я нимего не ожедаю\n",
            "iter 50000 ерли пы пишите носмальный или водти носмальный текрт у чтого роожбения котосый легко всодитать ркосее прего пы пре ршелали всапильно и волудите макримальный жалл за ворлешнее детпестое зашание кусра хотя конедно я нидего не ожебаю\n",
            "iter 60000 ерли бы бижите носмальный или водти носмальный текрт у чтого роопшения котосый легко всодитать ркосее брего бы бре ржелали всабильно и волудите макримальный палл за ворлежнее детбестое зажание кусра хотя конедно я нидего не опешаю\n",
            "iter 70000 ерли пы пижите носмальный или водти носмальный текрт у чтого рообшения котосый легко всодитать ркосее прего пы пре ржелали всапильно и волудите макримальный балл за ворлежнее детпестое зажание кусра хотя конедно я нидего не обешаю\n",
            "iter 80000 ерли пы пижите носмальный или водти носмальный текрт у чтого рообшения котосый легко всодитать ркосее прего пы пре ржелали всапильно и волудите макримальный балл за ворлежнее детпестое зажание кусра хотя конедно я нидего не обешаю\n",
            "iter 90000 ерти пы пижиле новзатьный ити содли новзатьный лекрл у шлого рообмения коловый тегко сводилаль рковее прего пы пре ржетати свапитьно и сотудиле закризатьный батт ча сортежнее делпевлое чажание кувра холя конедно я нидего не обемаю\n",
            "iter 100000 ерти пы пимиле носзатьный ити водли носзатьный лекрл у блого роочшения колосый тегко всодилаль ркосее прего пы пре рметати всапитьно и вотудиле закризатьный чатт жа вортемнее делпеслое жамание кусра холя конедно я нидего не очешаю\n",
            "iter 110000 ерти пы пимиле новзатьный ити содли новзатьный лекрл у шлого роожбения коловый тегко сводилаль рковее прего пы пре рметати свапитьно и сотудиле закризатьный жатт ча сортемнее делпевлое чамание кувра холя конедно я нидего не ожебаю\n",
            "iter 120000 ерти пы пимиле новзатьный ити содли новзатьный лекрл у блого роочшения коловый тегко сводилаль рковее прего пы пре рметати свапитьно и сотудиле закризатьный чатт жа сортемнее делпевлое жамание кувра холя конедно я нидего не очешаю\n",
            "iter 130000 ерли пы пимите носкальный или вочти носкальный тедрт у штого роожбения дотосый легдо всочитать рдосее прего пы пре рмелали всапильно и волучите кадрикальный жалл за ворлемнее четпестое замание дусра хотя донечно я ничего не ожебаю\n",
            "iter 140000 если вы вимите норшальный или подти норшальный текст у чтого сообжения который легко продитать скорее всего вы все смелали правильно и полудите шаксишальный балл за послемнее детвертое замание курса хотя конедно я нидего не обежаю\n",
            "iter 150000 если вы вимите норзальный или подти норзальный текст у чтого сообжения который легко продитать скорее всего вы все смелали правильно и полудите заксизальный балл ша послемнее детвертое шамание курса хотя конедно я нидего не обежаю\n",
            "iter 160000 если вы вимите норзальный или подти норзальный текст у штого соожчения который легко продитать скорее всего вы все смелали правильно и полудите заксизальный жалл ба послемнее детвертое бамание курса хотя конедно я нидего не ожечаю\n",
            "iter 170000 если вы вимите норзальный или подти норзальный текст у ютого сообшения который легко продитать скорее всего вы все смелали правильно и полудите заксизальный балл ча послемнее детвертое чамание курса хотя конедно я нидего не обешаж\n",
            "iter 180000 если вы вимите норзальный или подти норзальный текст у штого соожчения который легко продитать скорее всего вы все смелали правильно и полудите заксизальный жалл ба послемнее детвертое бамание курса хотя конедно я нидего не ожечаю\n",
            "iter 190000 если вы вимите норшальный или подти норшальный текст у чтого сообжения который легко продитать скорее всего вы все смелали правильно и полудите шаксишальный балл за послемнее детвертое замание курса хотя конедно я нидего не обежаю\n",
            "iter 200000 если вы вимите норкальный или почти норкальный тедст у штого соожбения доторый легдо прочитать сдорее всего вы все смелали правильно и получите кадсикальный жалл за послемнее четвертое замание дурса хотя донечно я ничего не ожебаю\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_task = decode_text(TASK, result_decrypt_dict_task)\n",
        "decoded_task"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Dk5w8w_5JVr_",
        "outputId": "df459331-839f-4356-904a-1f92a690794c"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'если вы вимите норкальный или почти норкальный тедст у штого соожбения доторый легдо прочитать сдорее всего вы все смелали правильно и получите кадсикальный жалл за послемнее четвертое замание дурса хотя донечно я ничего не ожебаю'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DECODED = 'если вы видите нормальный или почти нормальный текст у этого сообщения который легко прочитать скорее всего вы все сделали правильно и получите максимальный балл за последнее четвертое задание курса хотя конечно я ничего не обещаю'"
      ],
      "metadata": {
        "id": "P-sODszjjSeZ"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(correct_symbols(DECODED, decoded_task ))\n",
        "print(accuracy(DECODED, decoded_task ))\n",
        "print(\"Не распознано символов:\", 33 - len(correct_symbols(DECODED, decoded_task )))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNQLnOfljmo7",
        "outputId": "a0e09e5f-dbee-4ca8-d7aa-8598af7dcc15"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'с', 'з', 'и', 'х', 'е', 'а', 'ю', 'р', 'в', 'й', 'г', 'ы', 'о', ' ', 'л', 'н', 'т', 'ч', 'п', 'я', 'ь', 'у'}\n",
            "0.908695652173913\n",
            "Не распознано символов: 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вроде бы, получилось. Но сила рандома велика, иногда читабельно уже на 20 000 итерации, а иногда еле-еле к 200 000.\n"
      ],
      "metadata": {
        "id": "T89I8tAoZebK"
      }
    }
  ]
}